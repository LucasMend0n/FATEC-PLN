## Aula 12 - 30/05

### Introdução — Modelo de Rede Neural Recorrente (RNN)

Nesta aula, trabalhamos a construção de modelos de Redes Neurais Recorrentes (RNN) para o processamento de sequências de texto. O foco foi demonstrar o funcionamento das RNNs utilizando a biblioteca TensorFlow/Keras, desde a preparação dos dados até o treinamento da rede.

---

### Tópicos abordados:

1. **Configuração do ambiente**  
   - Importação das bibliotecas necessárias: TensorFlow, Keras, Numpy.

2. **Preparação dos dados**  
   - Tokenização de textos e transformação em sequências numéricas.
   - Padding das sequências para padronização do comprimento.

3. **Construção do modelo RNN**  
   - Uso da camada `Embedding` para representar palavras em vetores.
   - Implementação de uma camada `SimpleRNN` para processar sequências temporais.
   - Camada `Dense` para a previsão final.

4. **Compilação e treinamento do modelo**  
   - Definição de função de perda e otimizador.
   - Treinamento da rede com dados preparados.

5. **Avaliação e previsão**  
   - Análise do desempenho do modelo.
   - Geração de previsões com base em novas entradas de texto.

---

### Objetivo

O objetivo do notebook foi introduzir o uso de Redes Neurais Recorrentes aplicadas a dados textuais, ensinando como preparar os dados, construir, treinar e avaliar uma RNN simples utilizando TensorFlow/Keras.

---

### Técnicas utilizadas

- Tokenização de textos com Keras
- Padding de sequências
- Construção de redes com camadas Embedding e SimpleRNN
- Treinamento de modelos sequenciais
- Análise de vocabulário e índices de palavras

---

### Observações

A aula apresentou uma abordagem prática e introdutória sobre Redes Neurais Recorrentes, destacando a importância de transformar dados textuais em sequências numéricas e demonstrando como o TensorFlow/Keras facilita a construção de modelos de PLN para tarefas como modelagem de linguagem e classificação de texto sequencial.
