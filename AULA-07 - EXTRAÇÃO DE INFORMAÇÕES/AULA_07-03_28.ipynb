{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Aula 07 - Descoberta de conhecimento"
      ],
      "metadata": {
        "id": "YLA6NohRi6oz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exemplo 01. NER com spaCy"
      ],
      "metadata": {
        "id": "Y7fGrKJOjhcm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install spacy\n",
        "!python -m spacy download pt_core_news_sm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DkOepVWbjCXM",
        "outputId": "b6a6ea7c-ee89-4906-ab2f-e546741aadb8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.11/dist-packages (3.8.5)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.12)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.11/dist-packages (from spacy) (8.3.4)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.15.2)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (4.67.1)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.11.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.1.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy) (75.2.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (24.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.5.0)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.33.1)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.13.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2025.1.31)\n",
            "Requirement already satisfied: blis<1.3.0,>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.2.1)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.21.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy) (3.0.2)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.18.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.17.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n",
            "Collecting pt-core-news-sm==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/pt_core_news_sm-3.8.0/pt_core_news_sm-3.8.0-py3-none-any.whl (13.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.0/13.0 MB\u001b[0m \u001b[31m58.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pt-core-news-sm\n",
            "Successfully installed pt-core-news-sm-3.8.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('pt_core_news_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "\n",
        "nlp = spacy.load(\"pt_core_news_sm\")\n",
        "\n",
        "texto = \"Steve Jobs, CEO da Apple, visitou o Brasil em maio de 2009 para discutir investimentos de R$ 5 bilhoes.\"\n",
        "\n",
        "doc = nlp(texto)\n",
        "\n",
        "for entidade in doc.ents:\n",
        "  print(f\"{entidade.text} - {entidade.label_}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5zn1oqrUj-BV",
        "outputId": "79fb4b11-00be-4dcf-a032-b014c0bab23d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Steve Jobs - PER\n",
            "Apple - ORG\n",
            "Brasil - LOC\n",
            "R$ - MISC\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exemplo 02. NER com NLTK"
      ],
      "metadata": {
        "id": "tI1acIfrkDdA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.tag import pos_tag\n",
        "from nltk.chunk import ne_chunk\n",
        "\n",
        "#nltk.download('punkt_tab')\n",
        "#nltk.download('maxent_ne_chunker_tab')\n",
        "#nltk.download('words')\n",
        "#nltk.download('averaged_perceptron_tagger_eng')\n",
        "\n",
        "texto = \"Barack Obama foi presidente dos Estados Unidos e ganhou o Premio Nobel da Paz.\"\n",
        "\n",
        "# Tokenizaçao e POS tagging\n",
        "tokens = word_tokenize(texto)\n",
        "tags = pos_tag(tokens)\n",
        "\n",
        "# Identificaçao de entidades\n",
        "entidades = ne_chunk(tags)\n",
        "\n",
        "print(entidades)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5lcqZblEkN7l",
        "outputId": "fa71ea56-263d-418d-d211-9a9ba05793f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(S\n",
            "  (PERSON Barack/NNP)\n",
            "  (ORGANIZATION Obama/NNP)\n",
            "  foi/NN\n",
            "  presidente/NN\n",
            "  dos/NN\n",
            "  (PERSON Estados/NNP Unidos/NNP)\n",
            "  e/NN\n",
            "  ganhou/NN\n",
            "  o/NN\n",
            "  Premio/NNP\n",
            "  Nobel/NNP\n",
            "  da/NN\n",
            "  Paz/NNP\n",
            "  ./.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exemplo 03. Extração de informações com expressões regulares"
      ],
      "metadata": {
        "id": "8TwXo50Cku5V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "texto = \"O pagamento deve ser feito ate 30 de junho de 2025.\"\n",
        "\n",
        "padrao = r\"\\d{1,2} de [a-zA-Z]+ de \\d{4}\"\n",
        "datas = re.findall(padrao, texto)\n",
        "\n",
        "print(datas)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ByWyRu0tk5jG",
        "outputId": "61a05176-6111-40ae-c6d6-af642299a6b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['30 de junho de 2025']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exemplo 04. Extração de informação com regras heurísticas e dicionários"
      ],
      "metadata": {
        "id": "flWLH2iBk7KV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "profissoes = [\"engenheiro\", \"cientista de dados\", \"medico\", \"advogado\"]\n",
        "\n",
        "texto = \"Joao e engenheiro de software e trabalha no Google.\"\n",
        "\n",
        "for profissao in profissoes:\n",
        "  if profissao in texto:\n",
        "    print(f\"Profissao identificada: {profissao}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Byso6hmlBgh",
        "outputId": "78ff3149-b185-4513-847b-05502047c2ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Profissao identificada: engenheiro\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exemplo 05. Mineração de textos com frequência de palavras e N-gramas"
      ],
      "metadata": {
        "id": "1kljeigIlj6I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.util import ngrams\n",
        "from collections import Counter\n",
        "\n",
        "texto = \"Mineracao de textos envolve analise de palavras, palavras importantes e padroes.\"\n",
        "palavras = nltk.word_tokenize(texto.lower())\n",
        "\n",
        "frequencia = Counter (palavras)\n",
        "print(frequencia.most_common(5))\n",
        "\n",
        "bigrams = list(ngrams(palavras, 2))\n",
        "print(bigrams)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ftEdrO36lpFi",
        "outputId": "fc8eaf05-bc81-4955-8e71-7161cd831692"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('de', 2), ('palavras', 2), ('mineracao', 1), ('textos', 1), ('envolve', 1)]\n",
            "[('mineracao', 'de'), ('de', 'textos'), ('textos', 'envolve'), ('envolve', 'analise'), ('analise', 'de'), ('de', 'palavras'), ('palavras', ','), (',', 'palavras'), ('palavras', 'importantes'), ('importantes', 'e'), ('e', 'padroes'), ('padroes', '.')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exemplo 06. Mineração de texto"
      ],
      "metadata": {
        "id": "3ntU3F6Cluow"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install gensim\n",
        "!pip install --force-reinstall gensim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 842
        },
        "id": "Y9MHUCHslts2",
        "outputId": "d40fe56f-4a36-47a3-98b8-fd150224a109"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.11/dist-packages (4.3.3)\n",
            "Requirement already satisfied: numpy<2.0,>=1.18.5 in /usr/local/lib/python3.11/dist-packages (from gensim) (1.26.4)\n",
            "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from gensim) (1.13.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from gensim) (7.1.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open>=1.8.1->gensim) (1.17.2)\n",
            "Collecting gensim\n",
            "  Using cached gensim-4.3.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.1 kB)\n",
            "Collecting numpy<2.0,>=1.18.5 (from gensim)\n",
            "  Using cached numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "Collecting scipy<1.14.0,>=1.7.0 (from gensim)\n",
            "  Using cached scipy-1.13.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "Collecting smart-open>=1.8.1 (from gensim)\n",
            "  Using cached smart_open-7.1.0-py3-none-any.whl.metadata (24 kB)\n",
            "Collecting wrapt (from smart-open>=1.8.1->gensim)\n",
            "  Using cached wrapt-1.17.2-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.4 kB)\n",
            "Using cached gensim-4.3.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.7 MB)\n",
            "Using cached numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "Using cached scipy-1.13.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.6 MB)\n",
            "Using cached smart_open-7.1.0-py3-none-any.whl (61 kB)\n",
            "Using cached wrapt-1.17.2-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (83 kB)\n",
            "Installing collected packages: wrapt, numpy, smart-open, scipy, gensim\n",
            "  Attempting uninstall: wrapt\n",
            "    Found existing installation: wrapt 1.17.2\n",
            "    Uninstalling wrapt-1.17.2:\n",
            "      Successfully uninstalled wrapt-1.17.2\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.26.4\n",
            "    Uninstalling numpy-1.26.4:\n",
            "      Successfully uninstalled numpy-1.26.4\n",
            "  Attempting uninstall: smart-open\n",
            "    Found existing installation: smart-open 7.1.0\n",
            "    Uninstalling smart-open-7.1.0:\n",
            "      Successfully uninstalled smart-open-7.1.0\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.13.1\n",
            "    Uninstalling scipy-1.13.1:\n",
            "      Successfully uninstalled scipy-1.13.1\n",
            "  Attempting uninstall: gensim\n",
            "    Found existing installation: gensim 4.3.3\n",
            "    Uninstalling gensim-4.3.3:\n",
            "      Successfully uninstalled gensim-4.3.3\n",
            "Successfully installed gensim-4.3.3 numpy-1.26.4 scipy-1.13.1 smart-open-7.1.0 wrapt-1.17.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "smart_open",
                  "wrapt"
                ]
              },
              "id": "ccbbb2f98f5b418d83b11f496fba94e2"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim import corpora, models\n",
        "\n",
        "documentos = [[\"mineração\", \"textos\", \"dados\"],\n",
        "[\"inteligência\", \"artificial\", \"aprendizado\"],\n",
        "[\"dados\", \"aprendizado\", \"estatistica\"]]\n",
        "\n",
        "dicionario = corpora.Dictionary(documentos)\n",
        "corpus = [dicionario.doc2bow(texto) for texto in documentos]\n",
        "\n",
        "lda_modelo = models.LdaModel(corpus, num_topics=2, id2word=dicionario)\n",
        "print(lda_modelo.print_topics())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iba0OChPl-rb",
        "outputId": "1ce61b32-b166-4b84-c388-f98442516704"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(0, '0.217*\"dados\" + 0.163*\"mineração\" + 0.162*\"textos\" + 0.128*\"estatistica\" + 0.118*\"aprendizado\" + 0.107*\"artificial\" + 0.105*\"inteligência\"'), (1, '0.244*\"aprendizado\" + 0.163*\"dados\" + 0.141*\"inteligência\" + 0.139*\"artificial\" + 0.123*\"estatistica\" + 0.095*\"textos\" + 0.095*\"mineração\"')]\n"
          ]
        }
      ]
    }
  ]
}